{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "filename = 'huck_finn.txt'\n",
    "\n",
    "file = open(filename, mode='r') # 'r' is to read\n",
    "\n",
    "text = file.read()\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(text)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Context Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "with open('huck_finn.txt','r') as file:\n",
    "\tprint(file.read())\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Flat files**: basic text files containing records. That is, table data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Ana' 13]\n",
      " ['Bob' 28]\n",
      " ['Carol' 55]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dic = {'Name': ['Ana', 'Bob', 'Carol'], 'Age': [13, 28, 55]}\n",
    "data = pd.DataFrame(dic)\n",
    "\n",
    "print(data.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pickled files**:\n",
    "\n",
    "~~~\n",
    "import pickle\n",
    "\n",
    "with open('pickled_fruit.pkl','rb') as file:\n",
    "\tdata = pickle.load(file)\n",
    "\n",
    "print(data)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excel files**:\n",
    "\n",
    "~~~\n",
    "import pandas as pd\n",
    "\n",
    "file = 'urbanpop.xlsx'\n",
    "\n",
    "data = pd.ExcelFile(file)\n",
    "\n",
    "print(data.sheet_names)\n",
    "\n",
    "df1 = data.parse('1960-1966')\n",
    "df2 = data.parse(0)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing the working directory:\n",
    "\n",
    "~~~\n",
    "import os\n",
    "wd = os.getcwd()\n",
    "os.listdir(wd)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAS and SATA files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "import pandas as pd\n",
    "\n",
    "# SAS files\n",
    "\n",
    "from sas7bdat import SAS7BDAT\n",
    "\n",
    "with SAS7BDAT('urbanpop.sas7bdat') as file:\n",
    "\tdf_sas = file.to_data_frame()\n",
    "\n",
    "# Stata files\n",
    "\n",
    "data = pd.read_stata('urbanpop.dta')\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HDF5 files\n",
    "\n",
    "Standard for storing large quantities of numerical data.\n",
    "\n",
    "Can scale to exabytes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "import h5py\n",
    "\n",
    "filename = 'H-H1_LOSC_4_V1-815411200-4096.hdf5'\n",
    "\n",
    "data = h5py.File(filename,'r')\n",
    "\n",
    "print(type(data))\n",
    "\n",
    "for key in data.keys():\n",
    "\tprint(key) # meta, quality, strain\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MATLAB files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "scipy.io.loadmat() # read .mat files\n",
    "\n",
    "scipy.io.savemat() # write .mat files\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "import scipy.io\n",
    "\n",
    "filename = 'workspace.mat'\n",
    "\n",
    "mat = scipy.io.loadmat(filename)\n",
    "\n",
    "print(type(mat)) # dict!\n",
    "\n",
    "# keys: MATLAB var names\n",
    "# values: objects assigned to vars\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro to relational DBs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SQLAlchemy:\n",
    "\n",
    "~~~\n",
    "from sqlalchemy import import create_engine\n",
    "\n",
    "engine = create_engine('sqlite:///Northwind.sqlite')\n",
    "\n",
    "table_names = engine.table_names()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Workflow of SQL querying**:\n",
    "\n",
    "- Import packages and functions\n",
    "- Create the database engine\n",
    "- Connect to the engine\n",
    "- Query the database\n",
    "- Save query results to a DataFrame\n",
    "- Close the connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecting...\n",
    "\n",
    "~~~\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "engine = create_engine('sqlite:///Northwind.sqlite')\n",
    "\n",
    "con = engine.connect()\n",
    "\n",
    "rs = con.execute('SELECT * FROM Orders')\n",
    "\n",
    "df = pd.DataFrame(rs.fecthall())\n",
    "\n",
    "df.columns = rs.keys()\n",
    "\n",
    "con.close()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using context manager:\n",
    "\n",
    "~~~\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "engine = create_engine('sqlite:///Northwind.sqlite')\n",
    "\n",
    "with engine.connect() as con:\n",
    "    rs = con.execute('SELECT OrderID, OrderDate, ShipName FROM Orders')\n",
    "\n",
    "    df = pd.DataFrame(rs.fecthmany(size=5))\n",
    "\n",
    "    df.columns = rs.keys()\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Pandas Way**:\n",
    "\n",
    "~~~\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "engine = create_engine('sqlite:///Northwind.sqlite')\n",
    "\n",
    "df = pd.read_sql_query('SELECT * FROM Orders',engine)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INNER JOIN in Python**:\n",
    "~~~\n",
    "df = pd.read_sql_query('SELECT OrderId, CompanyName FROM Orders INNER JOIN Customers on Orders.CustomerId = Customers.CustomersId',engine)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The urllib package\n",
    "\n",
    "- provides interface for fetching data across the web\n",
    "- urlopen() - accepts URLs instead of file names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv'\n",
    "\n",
    "urlretrieve(url,'winequality-white.csv') # saves locally\n",
    "~~~\n",
    "\n",
    "or\n",
    "\n",
    "~~~\n",
    "df = pd.read_csv(url,sep=';')\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### URL\n",
    "\n",
    "- Uniform/Universal Resource Locator\n",
    "- References to web resources\n",
    "- Focus: web addresses\n",
    "- Ingredients:\n",
    "\t- Protocol identifier - http:\n",
    "\t- Resource name - datacamp.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HTTP\n",
    "\n",
    "- HyperText Transfer Protocol\n",
    "- Foundation of data communication for the web\n",
    "- HTTPS - more secure form of HTTP\n",
    "- Going to a website = sending HTTP request\n",
    "\t- GET request\n",
    "- urlretrieve() performs a GET request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GET requests using urllib**\n",
    "\n",
    "~~~\n",
    "from urllib.request import urlopen, Request\n",
    "\n",
    "url = 'https://www.wikipedia.org/'\n",
    "\n",
    "request = Request(url)\n",
    "\n",
    "response = urlopen(request)\n",
    "\n",
    "html = response.read() # returns HTML code as a string\n",
    "\n",
    "response.close()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GET requests using requests**\n",
    "\n",
    "~~~\n",
    "import requests\n",
    "\n",
    "url = 'https://www.wikipedia.org/'\n",
    "\n",
    "r = requests.get(url)\n",
    "\n",
    "text = r.text # HTML as a string\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beautiful Soup\n",
    "\n",
    "- Parse and extract structured data from HTML\n",
    "- make tag soup beautiful and extract information\n",
    "\n",
    "~~~\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import requests\n",
    "\n",
    "url = 'https://www.crummy.com/software/BeautifulSoup/'\n",
    "\n",
    "r = requests.get(url)\n",
    "\n",
    "html_doc = r.text\n",
    "\n",
    "soup = BeautifulSoup(html_doc)\n",
    "print(soup.prettify())\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "\n",
    "# Import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Specify url\n",
    "url = 'https://www.python.org/~guido/'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Extracts the response as html: html_doc\n",
    "html_doc = r.text\n",
    "\n",
    "# create a BeautifulSoup object from the HTML: soup\n",
    "soup = BeautifulSoup(html_doc)\n",
    "\n",
    "# Print the title of Guido's webpage\n",
    "print(soup.title)\n",
    "\n",
    "# Find all 'a' tags (which define hyperlinks): a_tags\n",
    "a_tags = soup.find_all('a')\n",
    "\n",
    "# Print the URLs to the shell\n",
    "for link in a_tags:\n",
    "    print(link.get('href'))\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### APIs\n",
    "\n",
    "- Application Programming Interface\n",
    "- Protocols and routines\n",
    "\t- Building and interacting with software applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JSONs\n",
    "\n",
    "- JavaScript Object Notation\n",
    "- Real-time server-to-browser communication\n",
    "- Human readable\n",
    "\n",
    "~~~\n",
    "import json\n",
    "\n",
    "with open('snakes.json','r') as json_file:\n",
    "\tjson_data = json.load(json_file) # dict\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Connecting to an API in Python**\n",
    "\n",
    "~~~\n",
    "import requests\n",
    "\n",
    "url = 'http://www.omdbapi.com/?t=hackers'\n",
    "\n",
    "r.requests.get(url)\n",
    "\n",
    "json_data = r.json()\n",
    "\n",
    "for key, value in json_data.items():\n",
    "\tprint(key + ' : ', value)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What was that URL?**\n",
    "\n",
    "- http - making an HTTP request\n",
    "- www.omdbapi.com - querying the OMDB API\n",
    "- ?t=hackers\n",
    "\t- Query string\n",
    "\t- Return data for a movie with title (t) 'Hackers'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Access the Twitter API\n",
    "\n",
    "**Using Tweepy: Authentication handler**\n",
    "\n",
    "~~~\n",
    "import tweepy, json\n",
    "\n",
    "access_token = '...'\n",
    "access_token_secret = '...'\n",
    "consumer_key = '...'\n",
    "consumer_secret = '...'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "~~~\n",
    "\n",
    "**Tweepy: define stream listener class**\n",
    "\n",
    "~~~\n",
    "class MyStreamListener(tweepy.StreamListener):\n",
    "\tdef __init__(self, api=None):\n",
    "\t\tsuper(MyStreamListener, self).__init__()\n",
    "\t\tself.num_tweets = 0\n",
    "\t\tself.file = open('tweets.txt','w')\n",
    "\n",
    "\tdef on_status(self, status):\n",
    "\t\ttweet = status._json\n",
    "\t\tself.file.write(json.dumps(tweet) + '\\n')\n",
    "\t\ttweet_list.append(status)\n",
    "\t\tself.num_tweets += 1\n",
    "\t\tif self.num_tweets < 100:\n",
    "\t\t\treturn True\n",
    "\t\telse:\n",
    "\t\t\treturn False\n",
    "\t\tself.file.close()\n",
    "~~~\n",
    "\n",
    "**Using Tweepy: stream tweets**\n",
    "\n",
    "~~~\n",
    "l = MyStreamListener()\n",
    "stream = tweepy.Stream(auth,l)\n",
    "\n",
    "stream.filter(track=['apples','oranges'])\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**:\n",
    "\n",
    "~~~\n",
    "import re\n",
    "\n",
    "def word_in_text(word, text):\n",
    "    word = word.lower()\n",
    "    text = tweet.lower()\n",
    "    match = re.search(word, text)\n",
    "\n",
    "    if match:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# Initialize list to store tweet counts\n",
    "[clinton, trump, sanders, cruz] = [0, 0, 0, 0]\n",
    "\n",
    "# Iterate through df, counting the number of tweets in which\n",
    "# each candidate is mentioned\n",
    "for index, row in df.iterrows():\n",
    "    clinton += word_in_text('clinton', row['text'])\n",
    "    trump += word_in_text('trump', row['text'])\n",
    "    sanders += word_in_text('sanders', row['text'])\n",
    "    cruz += word_in_text('cruz', row['text'])\n",
    "\n",
    "\n",
    "# Import packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set seaborn style\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "# Create a list of labels:cd\n",
    "cd = ['clinton', 'trump', 'sanders', 'cruz']\n",
    "\n",
    "# Plot histogram\n",
    "ax = sns.barplot(cd, [clinton, trump, sanders, cruz])\n",
    "ax.set(ylabel=\"count\")\n",
    "plt.show()\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
