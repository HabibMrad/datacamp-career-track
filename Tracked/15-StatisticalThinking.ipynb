{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory data analysis (EDA)\n",
    "\n",
    "- The process of organizing, plotting, and summarizing a data set.\n",
    "\n",
    "\"Exploratory data analysis can never be the whole story, but nothing else can serve as the foundation stone.\" (John Tukey)\n",
    "\n",
    "#### Plotting a histogram\n",
    "\n",
    "- Always label your axes!\n",
    "\n",
    "#### Seaborn\n",
    "\n",
    "- An excellent Matplotlib-based statistical data visualization package written by Michael Waskom\n",
    "\n",
    "~~~\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set() # Set aesthetic parameters.\n",
    "\n",
    "_ = plt.hist(df_swing['dem_share'])\n",
    "_ = plt.xlabel('percent of vote for Obama')\n",
    "_ = plt.ylabel('number of counties')\n",
    "plt.show()\n",
    "~~~\n",
    "\n",
    "#### Bee swarm plot\n",
    "\n",
    "~~~\n",
    "_ = sns.swarmplot(x='state', y='dem_share', data=df_swing)\n",
    "\n",
    "_ = plt.xlabel('state')\n",
    "_ = plt.ylabel('percent of vote for Obama')\n",
    "\n",
    "plt.show()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Empirical Cumulative Distribution Function (ECDF)\n",
    "\n",
    "~~~\n",
    "import numpy as np\n",
    "\n",
    "x = np.sort(df_swing['dem_share'])\n",
    "\n",
    "y = np.arange(1, len(x)+1) / len(x)\n",
    "\n",
    "_ = plt.plot(x, y, marker='.', linestyle='none')\n",
    "\n",
    "_ = plt.xlabel('percent of vote for Obama')\n",
    "_ = plt.ylabel('ECDF')\n",
    "\n",
    "plt.margins(0.02)\n",
    "\n",
    "plt.show()\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean\n",
    "\n",
    "$ \\bar{x} = \\displaystyle\\frac{1}{n} \\displaystyle\\sum_{i=1}^{n} x_i$\n",
    "\n",
    "~~~\n",
    "import numpy as np\n",
    "\n",
    "print(np.mean(dem_share_PA))\n",
    "~~~\n",
    "\n",
    "- Heavily influenced by outliers.\n",
    "\n",
    "#### Median\n",
    "\n",
    "- Middle value of a data set\n",
    "\n",
    "~~~\n",
    "print(np.median(dem_share_PA))\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Percentile\n",
    "\n",
    "~~~\n",
    "np.percentile(df_swing['dem_share'], [25, 50, 75])\n",
    "~~~\n",
    "\n",
    "#### Box plot\n",
    "\n",
    "~~~\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "_ = sns.boxplot(x='east_west', y='dem_share', data=df_all_states)\n",
    "\n",
    "_ = plt.xlabel('region')\n",
    "_ = plt.ylabel('percent of vote for Obama')\n",
    "\n",
    "plt.show()\n",
    "~~~\n",
    "\n",
    "- Middle of the box: median\n",
    "- Edges of the box: 25th and 75th percentiles\n",
    "- Total height of the box: IQR (middle 50% of data)\n",
    "- Whiskers: $\\pm$ 1.5 IQR\n",
    "- Outside of whiskers: outliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance\n",
    "\n",
    "- Average squared distance from the mean.\n",
    "\n",
    "$\\sigma^2 = \\displaystyle\\frac{1}{n} \\displaystyle\\sum_{i=1}^{n} \\big(x_i - \\bar{x}\\big)^2$\n",
    "\n",
    "~~~\n",
    "np.var(dem_share_FL)\n",
    "~~~\n",
    "\n",
    "#### Std Deviation\n",
    "\n",
    "- Square root of the variance\n",
    "\n",
    "$\\sigma = \\sqrt{\\sigma^2}$\n",
    "\n",
    "~~~\n",
    "np.std(dem_share_FL)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covariance\n",
    "\n",
    "- A measure of how two quantities vary *together*\n",
    "- The mean of the product of the differences of each data point to the means (x and y)\n",
    "\n",
    "$Cov(x,y) = \\displaystyle\\frac{1}{n} \\displaystyle\\sum_{i=1}^{n} \\big(x_i - \\bar{x}\\big)\\big(y_i - \\bar{y}\\big)$\n",
    "\n",
    "~~~\n",
    "np.cov(x,y) # covariance MATRIX [cov(x,x), cov(x,y); cov(y,x), cov(y,y)]\n",
    "~~~\n",
    "\n",
    "#### Pearson correlation coefficient\n",
    "\n",
    "$\\rho_{x,y} = \\displaystyle\\frac{Cov(x,y)}{\\sigma_{x}\\ \\sigma_{y}}$\n",
    "\n",
    "- Variability of the data due to codependence (covariance) divided by the independent variability (std. deviations).\n",
    "- ranges from -1 to 1\n",
    "\n",
    "~~~\n",
    "np.corrcoef(x,y) # correlation MATRIX\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability distribution\n",
    "\n",
    "- A mathematical description of outcomes\n",
    "\n",
    "#### Poisson Distribution\n",
    "\n",
    "- Limit of the Binomial distribution for low probability of success and large number of Bernoulli trials - that is, for rare events.\n",
    "\n",
    "#### The exponential distribution\n",
    "\n",
    "- The waiting time between arrivals of a Poisson process is Exponentially distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal parameters\n",
    "\n",
    "- Parameter values that bring the model in closest agreement with the data\n",
    "\n",
    "#### Packages to do statistical inference\n",
    "\n",
    "- scipy.stats\n",
    "- statsmodels\n",
    "- numpy (hacker stats)\n",
    "\n",
    "### Least Squares\n",
    "\n",
    "- The process of finding the parameters for which the sum of the squares of the residuals is minimal.\n",
    "\n",
    "#### Least squares with *np.polyfit()*\n",
    "\n",
    "~~~\n",
    "slope, intercept = np.polyfit(total_votes,dem_share, 1)\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling an array\n",
    "\n",
    "Data:\n",
    "~~~\n",
    "[23.3, 27.1, 24.3, 25.7, 26.0] # Mean = 25.2\n",
    "~~~\n",
    "\n",
    "Resampled data (with replacement):\n",
    "~~~\n",
    "[27.1, 26.0, 23.3, 25.7, 23.3] # Mean = 25.08\n",
    "~~~\n",
    "\n",
    "### Bootstrapping\n",
    "\n",
    "- The use of resampled data to perform statistical inference.\n",
    "- Bootstrap sample: a resampled array of data.\n",
    "- Bootstrap replicate: a statistic computed from a resampled array.\n",
    "\n",
    "#### Resampling engine: *np.random.choice()*\n",
    "\n",
    "~~~\n",
    "import numpy as np\n",
    "\n",
    "bs_sample = np.random.choice(data, size=len(data))\n",
    "\n",
    "print(np.mean(bs_sample))\n",
    "print(np.median(bs_sample))\n",
    "print(np.std(bs_sample))\n",
    "~~~\n",
    "\n",
    "#### Bootstrap replicate function\n",
    "\n",
    "~~~\n",
    "def bootstrap_replicate_1d(data, func):\n",
    "\t\"\"\"Generate bootstrap replicate of 1D data.\"\"\"\n",
    "\tbs_sample = np.random.choice(data,size=len(data))\n",
    "\treturn func(bs_sample)\n",
    "~~~\n",
    "\n",
    "#### Many bootstrap replicates\n",
    "\n",
    "~~~\n",
    "N = 10000\n",
    "\n",
    "bs_replicates = np.empty(N)\n",
    "\n",
    "for i in range(N):\n",
    "\tbs_replicates[i] = bootstrap_replicate_1d(\n",
    "\t\t\tmichelson_speed_of_light, np.mean)\n",
    "\n",
    "_ = plt.hist(bs_replicates, bins=30, normed=True)\n",
    "_ = plt.xlabel('mean speed of light (km/s)')\n",
    "_ = plt.ylabel('PDF')\n",
    "\n",
    "plt.show()\n",
    "~~~\n",
    "\n",
    "### Confidence interval of a statistic\n",
    "\n",
    "- If we repeated measurements over and over again, $p$% of the observed values would lie within the $p$% confidence interval.\n",
    "\n",
    "#### Bootstrap confidence interval\n",
    "\n",
    "~~~\n",
    "ci = np.percentile(bs_replicates, [2.5, 97.5]) # 95%\n",
    "~~~\n",
    "\n",
    "In fact, it can be shown theoretically that under not-too-restrictive conditions, the value of the mean will always be Normally distributed. (This does not hold in general, just for the mean and a few other statistics.) The standard deviation of this distribution, called the standard error of the mean, or SEM, is given by the standard deviation of the data divided by the square root of the number of data points. I.e., for a data set, sem = np.std(data) / np.sqrt(len(data)).\n",
    "\n",
    "### Nonparametric inference\n",
    "\n",
    "- Make no assumptions about the model or probability distribution underlying the data.\n",
    "\n",
    "### Pairs bootstrap for linear regression\n",
    "\n",
    "- Resample data in pairs.\n",
    "- Compute slope and intercept from resampled data.\n",
    "- Each slope and intercept is a bootstrap replicate.\n",
    "\n",
    "#### Generating a pairs bootstrap sample\n",
    "\n",
    "~~~\n",
    "inds = np.arange(len(total_votes)) # obtaining indices\n",
    "\n",
    "bs_inds = np.random.choice(inds,len(inds)) # resampling indices\n",
    "\n",
    "bs_total_votes = total_votes[bs_inds]\n",
    "bs_dem_share = dem_share[bs_inds]\n",
    "\n",
    "bs_slope, bs_intercept = np.polyfit(bs_total_votes, bs_dem_share, 1)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis testing\n",
    "\n",
    "- Assessment of how reasonable the observed data are assuming a hypothesis is true.\n",
    "- Null hypothesis: another name for the hypothesis you are testing.\n",
    "\n",
    "#### Permutation\n",
    "\n",
    "- Random reordering of entries in an array.\n",
    "- Generating a permutation sample:\n",
    "\n",
    "~~~\n",
    "import numpy as np\n",
    "\n",
    "dem_share_both = np.concatenate((dem_share_PA, dem_share_OH))\n",
    "\n",
    "dem_share_perm = np.random.permutation(dem_share_both)\n",
    "\n",
    "perm_sample_PA = dem_share_perm[:len(dem_share_PA)]\n",
    "perm_sample_OH = dem_share_perm[len(dem_share_PA):]\n",
    "~~~\n",
    "\n",
    "### Test statistic\n",
    "\n",
    "- A single number that can be computed from observed data and from data you simulate under the null hypothesis.\n",
    "- It serves as a basis of comparison between the two.\n",
    "\n",
    "### p-value\n",
    "\n",
    "- The probability of obtaining a value of your test statistic that is at least as extreme as what was observed, under the assumption the null hypothesis is true.\n",
    "\n",
    "- NOT the probability that the null hypothesis is true.\n",
    "\n",
    "- Statistical significance: determined by the smallness of a p-value -> Null hypothesis significance testing (NHST)\n",
    "\n",
    "### Pipeline for hypothesis testing\n",
    "\n",
    "1. Clearly state the null hypothesis.\n",
    "2. Define your test statistic.\n",
    "3. Generate many sets of simulated data assuming the null hypothesis is true.\n",
    "4. Compute the test statistic for each simulated data set.\n",
    "5. The p-value is the fraction of your simulated data for which the test statistic is at least as extreme as for the real data.\n",
    "\n",
    "### Example\n",
    "\n",
    "#### Null hypothesis\n",
    "\n",
    "- The true mean speed of light in Michelson's experiments was actually Newcomb's reported value.\n",
    "\n",
    "#### Shifting the Michelson data\n",
    "\n",
    "~~~\n",
    "newcomb_value = 299860\n",
    "\n",
    "michelson_shifted = michelson_speed_of_light \\\n",
    "\t- np.mean(michelson_speed_of_light) + newcomb_value\n",
    "~~~\n",
    "\n",
    "#### Calculating the test statistic\n",
    "\n",
    "~~~\n",
    "def diff_from_newcomb(data, newcomb_value=299860):\n",
    "\treturn np.mean(data) - newcomb_value\n",
    "\n",
    "diff_obs = diff_from_newcomb(michelson_speed_of_light)\n",
    "\n",
    "bs_replicates = draw_bs_reps(michelson_shifted,diff_from_newcomb,10000)\n",
    "\n",
    "p_value = np.sum(bs_replicates <= diff_observed) / 10000\n",
    "\n",
    "print(p_value)\n",
    "~~~\n",
    "\n",
    "### One sample test\n",
    "\n",
    "- Compare one set of data to a single number.\n",
    "\n",
    "### Two sample test\n",
    "\n",
    "- Compare two sets of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A/B test\n",
    "\n",
    "- Used by organizations to see if a strategy change gives a better result.\n",
    "- Null hypothesis: the test statistic is impervious to the change.\n",
    "\n",
    "### Hypothesis test of correlation\n",
    "\n",
    "- Posit null hypothesis: the two variables are completely uncorrelated.\n",
    "- Simulate data assuming null hypothesis is true.\n",
    "- Use Pearson correlation $\\rho$ as test statistic.\n",
    "- Compute the p-value as fraction of replicates that have $\\rho$ at least as large as observed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
