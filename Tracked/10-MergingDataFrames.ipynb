{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading multiple files\n",
    "\n",
    "~~~\n",
    "filenames = [...]\n",
    "\n",
    "dataframes = [pd.read_csv(filename) for filename in filenames]\n",
    "~~~\n",
    "\n",
    "#### Using glob\n",
    "\n",
    "~~~\n",
    "from glob import glob\n",
    "\n",
    "filenames = glob('sales*.csv')\n",
    "\n",
    "dataframes = [pd.read_csv(filename) for filename in filenames]\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reindexing DataFrames\n",
    "\n",
    "#### \"Indexes\" vs. \"Indices\"\n",
    "\n",
    "- indices: many index labels within Index data structures\n",
    "- indexes: many pandas Index data structures\n",
    "\n",
    "**Reindexing**\n",
    "\n",
    "~~~\n",
    "ordered = ['Jan', 'Apr', 'Jul', 'Oct']\n",
    "\n",
    "w_mean2 = w_mean.reindex(ordered)\n",
    "\n",
    "w_mean2.sort_index() # un-doing\n",
    "~~~\n",
    "\n",
    "from another df index\n",
    "\n",
    "~~~\n",
    "w_mean.reindex(w_max.index)\n",
    "~~~\n",
    "\n",
    "**Order matters!**\n",
    "\n",
    "w_max.reindex(w_mean.index) != w_mean.reindex(w_max.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arithmetic with Series & DataFrames\n",
    "\n",
    "#### Scalar multiplication\n",
    "\n",
    "~~~\n",
    "weather.loc['2013-07-01':'2013-07-07','PrecipitationIn'] * 2.54\n",
    "~~~\n",
    "\n",
    "#### Absolute temperature range\n",
    "\n",
    "~~~\n",
    "week1_range = weather.loc['2013-07-01':'2013-07-07',['Min TemperatureF','Max TemperatureF']]\n",
    "\n",
    "week1_mean = weather.loc['2013-07-01':'2013-07-07','Mean TemperatureF']\n",
    "\n",
    "week1_range.divide(week1_mean, axis='rows')\n",
    "~~~\n",
    "\n",
    "#### Percent changes\n",
    "\n",
    "~~~\n",
    "week1_mean.pct_change() * 100\n",
    "~~~\n",
    "\n",
    "#### Addition\n",
    "\n",
    "~~~\n",
    "bronze.add(silver, fill_value=0)\n",
    "~~~\n",
    "\n",
    "Chaining\n",
    "\n",
    "~~~\n",
    "bronze.add(silver,fill_value=0).add(gold,fill_value=0)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appending & concatenating Series\n",
    "\n",
    "#### append()\n",
    "\n",
    "- .append(): Series & DataFrame method\n",
    "- invocation:\n",
    "\t- s1.append(s2)\n",
    "- stacks the rows of s2 below s1\n",
    "- does not adjust the index\n",
    "\t- .reset_index(drop=True)\n",
    "\n",
    "#### concat()\n",
    "\n",
    "- concat(): pandas module function\n",
    "- invocation:\n",
    "\t- pd.concat([s1, s2, s3])\n",
    "- can stack row-wise or column-wise\n",
    "- does no adjust the index\n",
    "\t- parameter: ignore_index=True\n",
    "\n",
    "#### concat() & .append()\n",
    "\n",
    "- Equivalence of concat() & .append()\n",
    "\t- result1 = pd.concat([s1,s2,s3])\n",
    "\t- result2 = s1.append(s2).append(s3)\n",
    "- result1 == result2 element-wise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using multi-index on rows\n",
    "\n",
    "~~~\n",
    "rain1314 = pd.concat([rain2013,rain2014],keys=[2013,2014],axis=0)\n",
    "~~~\n",
    "\n",
    "#### Using multi-index on columns\n",
    "\n",
    "~~~\n",
    "rain1314 = pd.concat([rain2013,rain2014],keys=[2013,2014],axis='columns')\n",
    "~~~\n",
    "\n",
    "#### pd.concat() with dict\n",
    "\n",
    "~~~\n",
    "rain_dict = {2013: rain2013, 2014: rain2014}\n",
    "\n",
    "rain1314 = pd.concat(rain_dict,axis='columns')\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "\n",
    "# Sort the entries of medals: medals_sorted\n",
    "medals_sorted = medals.sort_index(level=0)\n",
    "\n",
    "# Print the number of Bronze medals won by Germany\n",
    "print(medals_sorted.loc[('bronze','Germany')])\n",
    "\n",
    "# Print data about silver medals\n",
    "print(medals_sorted.loc['silver'])\n",
    "\n",
    "# Create alias for pd.IndexSlice: idx\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "# Print all the data on medals won by the United Kingdom\n",
    "print(medals_sorted.loc[idx[:,'United Kingdom'],:])\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "# Concatenate dataframes: february\n",
    "february = pd.concat(dataframes,keys=['Hardware', 'Software', 'Service'],axis=1)\n",
    "\n",
    "# Print february.info()\n",
    "print(february.info())\n",
    "\n",
    "# Assign pd.IndexSlice: idx\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "# Create the slice: slice_2_8\n",
    "slice_2_8 = february.loc['Feb 2, 2015':'Feb 8, 2015', idx[:, 'Company']]\n",
    "\n",
    "# Print slice_2_8\n",
    "print(slice_2_8)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "# Make the list of tuples: month_list\n",
    "month_list = [('january', jan), ('february', feb), ('march', mar)]\n",
    "\n",
    "# Create an empty dictionary: month_dict\n",
    "month_dict = {}\n",
    "\n",
    "for month_name, month_data in month_list:\n",
    "\n",
    "    # Group month_data: month_dict[month_name]\n",
    "    month_dict[month_name] = month_data.groupby('Company').sum()\n",
    "\n",
    "# Concatenate data in month_dict: sales\n",
    "sales = pd.concat(month_dict)\n",
    "\n",
    "# Print sales\n",
    "print(sales)\n",
    "\n",
    "# Print all sales by Mediacore\n",
    "idx = pd.IndexSlice\n",
    "print(sales.loc[idx[:, 'Mediacore'], :])\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outer & Inner joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      " [[0.1 1.1 2.1 3.1]\n",
      " [4.1 5.1 6.1 7.1]]\n",
      "\n",
      "B:\n",
      " [[0.2 1.2 2.2]\n",
      " [3.2 4.2 5.2]]\n",
      "\n",
      "C:\n",
      " [[ 0.3  1.3  2.3  3.3]\n",
      " [ 4.3  5.3  6.3  7.3]\n",
      " [ 8.3  9.3 10.3 11.3]]\n",
      "\n",
      "[[ True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True]]\n",
      "\n",
      "[[ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "A = np.arange(8).reshape(2,4) + 0.1\n",
    "B = np.arange(6).reshape(2,3) + 0.2\n",
    "C = np.arange(12).reshape(3,4) + 0.3\n",
    "\n",
    "print('A:\\n',A,end='\\n\\n')\n",
    "print('B:\\n',B,end='\\n\\n')\n",
    "print('C:\\n',C,end='\\n\\n')\n",
    "\n",
    "print(np.hstack([B, A]) == np.concatenate([B, A], axis=1),end='\\n\\n')\n",
    "print(np.vstack([A, C]) == np.concatenate([A, C], axis=0),end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "np.concatenate([A, B], axis=0) # incompatible columns\n",
    "\n",
    "np.concatenate([A, C], axis=1) # incompatible rows\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joins\n",
    "\n",
    "- joining tables: combining rows of multiple tables\n",
    "- Outer join\n",
    "\t- union of index sets (all labels, no repitition)\n",
    "\t- missing fields filled with NaN\n",
    "- Inner join\n",
    "\t- intersection of index sets (only common labels)\n",
    "\n",
    "**Concatenation & inner join**\n",
    "\n",
    "~~~\n",
    "pd.concat([population, unemployment], axis=1, join='inner')\n",
    "~~~\n",
    "\n",
    "**Concatenation & outer join**\n",
    "\n",
    "~~~\n",
    "pd.concat([population, unemployment], axis=1, join='outer') # outer: default\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging on\n",
    "\n",
    "~~~\n",
    "pd.merge(bronze, gold, on=['NOC','Country'], suffixes=['_bronze','_gold'])\n",
    "~~~\n",
    "\n",
    "~~~\n",
    "pd.merge(counties, cities, left_on='CITY NAME', right_on='City')\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging with inner join\n",
    "\n",
    "~~~\n",
    "pd.merge(bronze, gold, on=['NOC','Country'], suffixes=['_bronze','_gold'], how='inner') # inner: default\n",
    "~~~\n",
    "\n",
    "#### Merging with left join\n",
    "\n",
    "- keeps all rows of the left DF in the merged DF\n",
    "- for rows in the left DF with matches in the right DF:\n",
    "\t- non-joining columns of the right DF are appended to the left DF\n",
    "-for rows in the left DF with no matches in the right DF:\n",
    "\t- non-joining columns are filled with nulls\n",
    "- DataFrame.join(df) performs a left join by default (how='left')\n",
    "\n",
    "~~~\n",
    "pd.merge(bronze, gold, on=['NOC','Country'], suffixes=['_bronze','_gold'], how='left')\n",
    "~~~\n",
    "\n",
    "#### Merging with right join\n",
    "\n",
    "- keeps all rows of the right DF in the merged DF\n",
    "- for rows in the right DF with matches in the left DF:\n",
    "\t- non-joining columns of the left DF are appended to the right DF\n",
    "-for rows in the right DF with no matches in the left DF:\n",
    "\t- non-joining columns are filled with nulls\n",
    "\n",
    "~~~\n",
    "pd.merge(bronze, gold, on=['NOC','Country'], suffixes=['_bronze','_gold'], how='right')\n",
    "~~~\n",
    "\n",
    "#### Merging with outer join\n",
    "\n",
    "~~~\n",
    "pd.merge(bronze, gold, on=['NOC','Country'], suffixes=['_bronze','_gold'], how='outer')\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which should you use?\n",
    "\n",
    "- df1.append(df2): stacking vertically\n",
    "- pd.concat([df1,df2]):\n",
    "\t- stacking many horizontally or vertically\n",
    "\t- simple inner/outer join on Indexes\n",
    "- df1.join(df2): inner/outer/left/right joins on Indexes\n",
    "- pd.merge([df1,df2]): many joins on multiple columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordered merges\n",
    "\n",
    "~~~\n",
    "pd.merge_ordered(hardware, software, on=['Date','Company'], suffixes=['_hardware','_software'])\n",
    "~~~\n",
    "\n",
    "- By default, performs an outer join\n",
    "- Equivalent to chaining pd.merge() and .sorted_values()\n",
    "\n",
    "**Forward-filling**\n",
    "\n",
    "~~~\n",
    "pd.merge_ordered(stocks, gdp, on='Date', fill_method='ffill')\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
