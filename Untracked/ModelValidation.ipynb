{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model validation\n",
    "\n",
    "- Ensuring your model performs as expected on new data\n",
    "- Testing model performance on hold-out set\n",
    "- Selecting the best model, parameters, and accuracy metrics\n",
    "- Achieving the best accuracy for the data given\n",
    "\n",
    "### Modeling review\n",
    "\n",
    "~~~\n",
    "model = RandomForestRegressor(n_estimators=500, random_state=1111)\n",
    "\n",
    "model.fit(X=X_train, y=y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Mean Absolute Error\n",
    "print( mae(y_true=y_test, y_pred=predictions) )\n",
    "~~~\n",
    "\n",
    "- Mean Absolute Error:\n",
    "\n",
    "$ MAE = \\displaystyle\\frac{1}{n} \\displaystyle\\sum^n |y_i - \\hat{y}_i | $\n",
    "\n",
    "### Random Forest\n",
    "\n",
    "#### Regressor\n",
    "\n",
    "- Parameters:\n",
    "\t- n_estimatators: the number of trees in the forest\n",
    "\t- max_depth: the maximum depth of the trees.\n",
    "\t- random_state: random seed\n",
    "\n",
    "- Setting parameters:\n",
    "\n",
    "~~~\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor(n_estimators=50, max_depth=10)\n",
    "~~~\n",
    "\n",
    "or\n",
    "\n",
    "~~~\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr.n_estimators = 50\n",
    "rfr.max_depth = 10\n",
    "~~~\n",
    "\n",
    "- Feature importance:\n",
    "\n",
    "Print how important each column is to the model:\n",
    "\n",
    "~~~\n",
    "for i, item in enumerate(rfr.feature_importances_):\n",
    "\tprint(\"{0:s}: {1:.2f}\".format(X.columns[i], item))\n",
    "~~~\n",
    "\n",
    "#### Classifier\n",
    "\n",
    "~~~\n",
    "rfc = RandomForestClassifier(random_state=1111)\n",
    "rfc.get_params()\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Returns accuracy\n",
    "rfc.score(X_test, y_test)\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating train, test and validation data sets\n",
    "\n",
    "~~~\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=1111)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=11111)\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy metrics\n",
    "\n",
    "### Regression models\n",
    "\n",
    "#### Mean Absolute Error (MAE)\n",
    "\n",
    "$MAE = \\displaystyle\\frac{1}{n} \\displaystyle\\sum^n |y_i - \\hat{y}_i| $\n",
    "\n",
    "- Simplest and most intuitive metric\n",
    "- Treats all points equally\n",
    "- Not sensitive to outliers\n",
    "\n",
    "#### Mean Squared Error (MSE)\n",
    "\n",
    "$MSE = \\displaystyle\\frac{1}{n} \\displaystyle\\sum^n (y_i - \\hat{y}_i)^2 $\n",
    "\n",
    "- Most widely used regression metric\n",
    "- Allows outlier errors to contribute more to the overall error\n",
    "\n",
    "#### MAE *vs* MSE\n",
    "\n",
    "- Accuracy metris are always application specific\n",
    "- MAE and MSE error term are in different units and should not be compared\n",
    "\n",
    "### Classification models\n",
    "\n",
    "#### Confusion matrix\n",
    "\n",
    "~~~\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, test_predictions)\n",
    "print(cm)\n",
    "\n",
    "# cm[<true_category_index>, <predicted_category_index>]\n",
    "print(cm[1,0]) # False Negatives\n",
    "~~~\n",
    "\n",
    "#### Accuracy\n",
    "\n",
    "$\\displaystyle\\frac{TN + TP}{TN + TP + FN + FP}$\n",
    "\n",
    "~~~\n",
    "(cm[0,0] + cm[1,1])/sum(cm)\n",
    "~~~\n",
    "\n",
    "#### Precision\n",
    "\n",
    "$\\displaystyle\\frac{TP}{TP + FP}$\n",
    "\n",
    "~~~\n",
    "sum(cm[:,1])/sum(cm)\n",
    "~~~\n",
    "\n",
    "#### Recall\n",
    "\n",
    "$\\displaystyle\\frac{TP}{TP + FN}$\n",
    "\n",
    "~~~\n",
    "sum(cm[1,:])/sum(cm)\n",
    "~~~\n",
    "\n",
    "#### In scikit-learn\n",
    "\n",
    "~~~\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(precision_score(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred))\n",
    "~~~\n",
    "\n",
    "## The bias-variance trade-off\n",
    "\n",
    "### Variance\n",
    "\n",
    "- Following the training data too closely\n",
    "\t- Fails to generalize to the test data\n",
    "\t- Low training error but high testing error\n",
    "\t- Occurs when models are overfit and have high complexity\n",
    "\n",
    "### Bias\n",
    "\n",
    "- Failing to find the relationship between the data and the response\n",
    "\t- High training/testing error\n",
    "\t- Occurs when models are underfit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "\n",
    "- KFold() parameters\n",
    "\t- n_splits: numberof cross-validation splits\n",
    "\t- shuffle: boolean indicating to shuffle the data before splitting\n",
    "\t- random_state: random seed\n",
    "\n",
    "~~~\n",
    "from sklearn.mode_selection import KFold\n",
    "\n",
    "X = np.array(range(40))\n",
    "y = np.array([0] * 20 + [1] * 20)\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "splits = kf.split(X)\n",
    "\n",
    "for train_index, test_index in splits:\n",
    "\tprint(len(train_index),len(test_index)) # 32 8 (five times)\n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators=25, random_state=1111)\n",
    "\n",
    "errors = []\n",
    "\n",
    "for train_index, val_index in splits:\n",
    "\tX_train, y_train = X[train_index], y[train_index]\n",
    "\tX_val, y_val = X[val_index], y[val_index]\n",
    "\n",
    "\trfr.fit(X_train, y_train)\n",
    "\tpredictions = rfc.predictions(X_test)\n",
    "\terrors.append(<some_accuracy_metric>)\n",
    "\n",
    "print(np.mean(errors))\n",
    "~~~\n",
    "\n",
    "### In scikit-learn\n",
    "\n",
    "- cross_val_score()\n",
    "\t- estimator: the model to use\n",
    "\t- X: the predictor data set\n",
    "\t- y: the response array\n",
    "\t- cv: the number of CV splits\n",
    "\n",
    "- make_scorer()\n",
    "\n",
    "~~~\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "mae_scorer = make_scorer(mean_absolute_error)\n",
    "\n",
    "cv_results = cross_val_score(<estimator>, <X>, <y>, cv=5, scoring=mae_scorer)\n",
    "~~~\n",
    "\n",
    "### Leave-one-out Cross-Validation (LOOCV)\n",
    "\n",
    "- Use when:\n",
    "\t- the amount of training data is limited\n",
    "\t- you want the absolute best error estimate for new data\n",
    "- Be cautious when:\n",
    "\t- computational resources are limited\n",
    "\t- you have a lot of data\n",
    "\t- you have a lot of parameters to test\n",
    "\n",
    "#### Example\n",
    "\n",
    "~~~\n",
    "n = X.shape[0]\n",
    "mse = make_scorer(mean_squared_error)\n",
    "\n",
    "cv_results = cross_val_score(estimator, X, y, scoring=mse, cv=n)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "\n",
    "### Grid Searching\n",
    "\n",
    "- Benefits:\n",
    "\t- Tests every possible combination\n",
    "- Drawbacks:\n",
    "\t- Additional hyperparameters increase training time exponentially\n",
    "\n",
    "### Random Searching\n",
    "\n",
    "- Parameters:\n",
    "\t- estimator: the model to use\n",
    "\t- param_distributions: dictionary containing hyperparemeters and possible values\n",
    "\t- n_iter: number of iterations\n",
    "\t- scoring: scoring method to use\n",
    "\n",
    "~~~\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "\n",
    "param_dist = {'max_depth': [4, 6, 8, None],\n",
    "\t\t'max_features': range(2,11),\n",
    "\t\t'min_samples_split': range(2,11)}\n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators=20, random_state=1111)\n",
    "scorer = make_scorer(mean_absolute_error)\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=rfr, param_distributions=param_dist, n_iter=40, cv=5)\n",
    "\n",
    "random_search.fit(X, y)\n",
    "~~~\n",
    "\n",
    "#### Attributes\n",
    "\n",
    "- random_search.best_score_\n",
    "- random_search.best_params_\n",
    "- random_search.best_estimator_\n",
    "- random_search.cv_results_ [dict]\n",
    "\t- Example:\n",
    "\n",
    "\t~~~\n",
    "\t# Grouping the maximum depths\n",
    "\tmax_depth = [item['max_depth'] for item in random_search.cv_results_['params']]\n",
    "\tscores = list(random_search.cv_results_['mean_test_score'])\n",
    "\tdf = pd.DataFrame([max_depth, scores]).T\n",
    "\tdf.columns = ['Max Depth', 'Score']\n",
    "\tdf.groupby(['Max Depth']).mean()\n",
    "\t~~~\n",
    "\n",
    "#### Best Estimator\n",
    "\n",
    "- Predict new data:\n",
    "~~~\n",
    "random_search.best_estimator_.predict(<new_data>)\n",
    "~~~\n",
    "\n",
    "- Check the parameters:\n",
    "~~~\n",
    "random_search.best_estimator_.get_params()\n",
    "~~~\n",
    "\n",
    "- Save model to use later:\n",
    "~~~\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(random_search.best_estimator_, 'rfr_best_<date>.pkl')\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
