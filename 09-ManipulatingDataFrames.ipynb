{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing DataFrames\n",
    "\n",
    "- df[col][row]\n",
    "- df.loc[row_name(s),col_name(s)]\n",
    "- df.iloc[row_index(es),col_index(es)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "# Slice the row labels 'Perry' to 'Potter': p_counties\n",
    "p_counties = election.loc['Perry':'Potter']\n",
    "\n",
    "# Print the p_counties DataFrame\n",
    "print(p_counties)\n",
    "\n",
    "# Slice the row labels 'Potter' to 'Perry' in reverse order: p_counties_rev\n",
    "p_counties_rev = election.loc['Potter':'Perry':-1]\n",
    "\n",
    "# Print the p_counties_rev DataFrame\n",
    "print(p_counties_rev)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining filters\n",
    "\n",
    "~~~\n",
    "df[(df.salt >= 50) & (df.eggs < 200)] # and\n",
    "\n",
    "df[(df.salt >= 50) | (df.eggs < 200)] # or\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select columns with all nonzeros**\n",
    "\n",
    "~~~\n",
    "df.loc[:,df.all()]\n",
    "~~~\n",
    "\n",
    "**Select columns with any nonzeros**\n",
    "\n",
    "~~~\n",
    "df.loc[:,df.any()]\n",
    "~~~\n",
    "\n",
    "**Select columns with any Nans**\n",
    "\n",
    "~~~\n",
    "df.loc[:,df.isnull().any()]\n",
    "~~~\n",
    "\n",
    "**Select columns without NaNs**\n",
    "\n",
    "~~~\n",
    "df.loc[:,df.notnull().all()]\n",
    "~~~\n",
    "\n",
    "**Drop rows with any NaNs**\n",
    "\n",
    "~~~\n",
    "df.dropna(how='any') # how='all' drops all-NaN rows/cols\n",
    "~~~\n",
    "\n",
    "**Filtering/modifying a column based on another**\n",
    "\n",
    "~~~\n",
    "df.eggs[df.salt > 55] += 5\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "# Select the 'age' and 'cabin' columns: df\n",
    "df = titanic[['age','cabin']]\n",
    "\n",
    "# Print the shape of df\n",
    "print(df.shape)\n",
    "\n",
    "# Drop rows in df with how='any' and print the shape\n",
    "print(df.dropna(how='any').shape)\n",
    "\n",
    "# Drop rows in df with how='all' and print the shape\n",
    "print(df.dropna(how='all').shape)\n",
    "\n",
    "# Drop columns in titanic with less than 1000 non-missing values\n",
    "print(titanic.dropna(thresh=1000, axis='columns').info())\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame vectorized methods\n",
    "\n",
    "**Convert to dozen units**\n",
    "\n",
    "~~~\n",
    "df.floordiv(12)\n",
    "~~~\n",
    "\n",
    "or\n",
    "\n",
    "~~~\n",
    "import numpy as np\n",
    "\n",
    "np.floor_divide(df,12)\n",
    "~~~\n",
    "\n",
    "or\n",
    "\n",
    "~~~\n",
    "df.apply(lambda n: n//12)\n",
    "~~~\n",
    "\n",
    "#### Storing a transformation\n",
    "\n",
    "~~~\n",
    "df['dozens_of_eggs'] = df.eggs.floordiv(12)\n",
    "~~~\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manipulating the index\n",
    "\n",
    "~~~\n",
    "df.index = df.index.str.upper()\n",
    "~~~\n",
    "\n",
    "or\n",
    "\n",
    "~~~\n",
    "df.index = df.index.map(str.upper)\n",
    "~~~\n",
    "\n",
    "**Defining columns using other columns**\n",
    "\n",
    "~~~\n",
    "df['salty_eggs'] = df.salt + df.dozens_of_eggs\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "# Create the dictionary: red_vs_blue\n",
    "red_vs_blue = {'Obama':'blue','Romney':'red'}\n",
    "\n",
    "# Use the dictionary to map the 'winner' column to the new column: election['color']\n",
    "election['color'] = election['winner'].map(red_vs_blue)\n",
    "\n",
    "# Print the output of election.head()\n",
    "print(election.head())\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas Data Structures\n",
    "\n",
    "- Key building blocks\n",
    "\t- Indexes: sequence of labels\n",
    "\t- Series: 1D array with Index\n",
    "\t- DataFrames: 2D array with Series as column (and rows)\n",
    "- Indexes\n",
    "\t- Immutable (like dictionary keys)\n",
    "\t- Homogeneous in data type (like NumPy arrays)\n",
    "\n",
    "#### Assinging the index\n",
    "\n",
    "~~~\n",
    "unemployment.index = unemployment['Zip']\n",
    "\n",
    "del unemployment['Zip']\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical indexing\n",
    "\n",
    "**Setting index**\n",
    "\n",
    "~~~\n",
    "stocks =  stocks.set_index(['Symbol','Date'])\n",
    "# MultiIndex\n",
    "\n",
    "print(stocks.index.names)\n",
    "\n",
    "stocks.stocks.sort_index()\n",
    "~~~\n",
    "\n",
    "**Indexing**\n",
    "\n",
    "~~~\n",
    "stocks.loc[('CSCO','2016-10-04')] # Tuple!\n",
    "\n",
    "stocks.loc[('CSCO','2016-10-04'),'Volume']\n",
    "~~~\n",
    "\n",
    "**Slicing**\n",
    "\n",
    "- Outermost index:\n",
    "\n",
    "~~~\n",
    "stocks.loc['AAPL']\n",
    "\n",
    "stocks.loc['CSCO':'MSFT']\n",
    "~~~\n",
    "\n",
    "- Both indexes:\n",
    "\n",
    "~~~\n",
    "stocks.loc[(slice(None), slice('2016-10-03','2016-10-04')),:]\n",
    "~~~\n",
    "\n",
    "**Fancy indexing**\n",
    "\n",
    "- Outermost index\n",
    "\n",
    "~~~\n",
    "stocks.loc[(['AAPL','MSFT'], '2016-10-05'),:]\n",
    "\n",
    "stocks.loc[(['AAPL','MSFT'], '2016-10-05'),'Close']\n",
    "~~~\n",
    "\n",
    "- Innermost index\n",
    "\n",
    "~~~\n",
    "stocks.loc[('CSCO', ['2016-10-05','2016-10-03']),:]\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "# Look up data for NY in month 1: NY_month1\n",
    "NY_month1 = sales.loc[('NY',1),:]\n",
    "\n",
    "# Look up data for CA and TX in month 2: CA_TX_month2\n",
    "CA_TX_month2 = sales.loc[(['CA','TX'],2),:]\n",
    "\n",
    "# Look up data for all states in month 2: all_month2\n",
    "all_month2 = sales.loc[(slice(None),2),:]\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshaping DataFrames\n",
    "\n",
    "**Reshaping by pivoting**\n",
    "\n",
    "~~~\n",
    "trials.pivot(index='treatment',\n",
    "\t\tcolumns='gender',\n",
    "\t\tvalues='response')\n",
    "~~~\n",
    "\n",
    "**Pivoting multiple columns**\n",
    "\n",
    "~~~\n",
    "trials.pivot(index='treatment',\n",
    "\t\tcolumns='gender')\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking & unstacking DataFrames\n",
    "\n",
    "- Unstacking (long -> wider)\n",
    "\n",
    "~~~\n",
    "trials_by_gender = trials.unstack(level='gender')\n",
    "~~~\n",
    "\n",
    "or\n",
    "\n",
    "~~~\n",
    "trials_by_gender = trials.unstack(level=1)\n",
    "~~~\n",
    "\n",
    "- Stacking (wide -> longer)\n",
    "\n",
    "~~~\n",
    "trials_by_gender.stack(level='gender')\n",
    "~~~\n",
    "\n",
    "**Swapping levels**\n",
    "\n",
    "~~~\n",
    "swapped = df.swaplevel(0,1)\n",
    "\n",
    "sorted_df = swapped.sort_index()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Melting DataFrames\n",
    "\n",
    "~~~\n",
    "pd.melt(new_trials,id_vars=['treatment'],\n",
    "\tvalue_vars=['F','M'])\n",
    "~~~\n",
    "\n",
    "~~~\n",
    "pd.melt(new_trials, id_vars=['treatment'],\n",
    "\tvar_name='gender',value_name='response')\n",
    "~~~\n",
    "\n",
    "#### See pd.melt(): https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.melt.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pivot table\n",
    "\n",
    "Works when there repeated combinations of values;\n",
    "uses aggregation (default: avg)\n",
    "\n",
    "~~~\n",
    "more_trials.pivot_table(index='treatment',\n",
    "\t\t\tcolumns='gender',\n",
    "\t\t\tvalues='response',\n",
    "\t\t\taggfunc='count')\n",
    "~~~\n",
    "\n",
    "##### See pandas.DataFrame.pivot_table(): https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.DataFrame.pivot_table.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Groupby and count\n",
    "\n",
    "~~~\n",
    "sales.groupby('weekday').count()\n",
    "~~~\n",
    "\n",
    "- split by 'weekday'\n",
    "- apply count() function on each group\n",
    "- combine counts per group\n",
    "\n",
    "#### Aggregation/Reduction\n",
    "\n",
    "- Some reducing functions\n",
    "\t- mean()\n",
    "\t- std()\n",
    "\t- sum()\n",
    "\t- first(), last()\n",
    "\t- min(), max()\n",
    "\n",
    "#### Groupby and sum\n",
    "\n",
    "~~~\n",
    "sales.groupby('weekday')[['bread','butter']].sum()\n",
    "~~~\n",
    "\n",
    "#### Groupby and mean: multi-level index\n",
    "\n",
    "~~~\n",
    "sales.groupby(['city','weekday']).mean()\n",
    "~~~\n",
    "\n",
    "#### Groupby and sum: by Series\n",
    "\n",
    "~~~\n",
    "customers = pd.Series([...]) # has same index as sales\n",
    "\n",
    "sales.groupby(customers)['bread'].sum()\n",
    "~~~\n",
    "\n",
    "**Categorical data**\n",
    "\n",
    "~~~\n",
    "sales['weekday'].unique()\n",
    "\n",
    "sales['weekday'] = sales['weekday'].astype('category')\n",
    "~~~\n",
    "\n",
    "- Advantages:\n",
    "\t- uses less memory\n",
    "\t- speeds up operations like groupby()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "# Group titanic by 'pclass': by_class\n",
    "by_class = titanic.groupby('pclass')\n",
    "\n",
    "# Select 'age' and 'fare'\n",
    "by_class_sub = by_class[['age','fare']]\n",
    "\n",
    "# Aggregate by_class_sub by 'max' and 'median': aggregated\n",
    "aggregated = by_class_sub.agg(['max','median'])\n",
    "\n",
    "# Print the maximum age in each class\n",
    "print(aggregated.loc[:, ('age','max')])\n",
    "\n",
    "# Print the median fare in each class\n",
    "print(aggregated.loc[:,('fare','median')])\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "\n",
    "# Read the CSV file into a DataFrame and sort the index: gapminder\n",
    "gapminder = pd.read_csv('gapminder.csv',index_col=['Year','region','Country']).sort_index()\n",
    "\n",
    "# Group gapminder by 'Year' and 'region': by_year_region\n",
    "by_year_region = gapminder.groupby(level=['Year','region'])\n",
    "\n",
    "# Define the function to compute spread: spread\n",
    "def spread(series):\n",
    "    return series.max() - series.min()\n",
    "\n",
    "# Create the dictionary: aggregator\n",
    "aggregator = {'population':'sum', 'child_mortality':'mean', 'gdp':spread}\n",
    "\n",
    "# Aggregate by_year_region using the dictionary: aggregated\n",
    "aggregated = by_year_region.agg(aggregator)\n",
    "\n",
    "# Print the last 6 entries of aggregated \n",
    "print(aggregated.tail(6))\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "# Read file: sales\n",
    "sales = pd.read_csv('sales.csv',index_col='Date',parse_dates=True)\n",
    "\n",
    "# Create a groupby object: by_day\n",
    "by_day = sales.groupby(sales.index.strftime('%a'))\n",
    "\n",
    "# Create sum: units_sum\n",
    "units_sum = by_day['Units'].sum()\n",
    "\n",
    "# Print units_sum\n",
    "print(units_sum)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby and transformation\n",
    "\n",
    "- The z-score\n",
    "\n",
    "~~~\n",
    "def zscore(series):\n",
    "\treturn (series - series.mean()) / series.std()\n",
    "~~~\n",
    "\n",
    "- The automobile dataset\n",
    "\n",
    "~~~\n",
    "auto = pd.read_csv('auto-mpg.csv')\n",
    "~~~\n",
    "\n",
    "- MPG z-score\n",
    "\n",
    "~~~\n",
    "zscore(auto['mpg']).head()\n",
    "~~~\n",
    "\n",
    "- MPG z-score by year\n",
    "\n",
    "~~~\n",
    "auto.groupby('yr')['mpg'].transform(zscore).head()\n",
    "~~~\n",
    "\n",
    "#### Apply transformation and aggregation\n",
    "\n",
    "- The agg() method applies reduction\n",
    "- The transform() method applies a function element-wise to groups\n",
    "- In some cases, split-apply-combine operations do not neatly fall into aggregation or transformation: for those cases we use apply()\n",
    "\n",
    "~~~\n",
    "def zscore_with_year_and_name(group):\n",
    "\tdf = pd.DataFrame(\n",
    "\t\t\t{'mpg': zscore(group['mpg']),\n",
    "\t\t\t'year': group['yr'],\n",
    "\t\t\t'name': group['name']})\n",
    "\treturn df\n",
    "\n",
    "auto.groupby('yr').apply(zscore_with_year_and_name).head()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### groupby object\n",
    "\n",
    "~~~\n",
    "splitting = auto.groupby('yr')\n",
    "\n",
    "print(type(splitting)) # pandas.core.groupby.DataFrameGroupBy\n",
    "\n",
    "print(type(splitting.groups)) # dict\n",
    "\n",
    "print(splitting.groups.keys()) # The keys are the years\n",
    "\n",
    "# iteration\n",
    "for group_name, group in splitting:\n",
    "\tavg = group['mpg'].mean()\n",
    "\tprint(group_name,avg)\n",
    "\n",
    "# iteration and filtering\n",
    "for group_name, group in splitting:\n",
    "\tavg = group.loc[group['name'].str.contains('chevrolet'), 'mpg'].mean()\n",
    "\tprint(group_name,avg)\n",
    "\n",
    "# comprehension\n",
    "chevy_means = {year:group.loc[group['name'].str.contains('chevrolet'), 'mpg'].mean()\n",
    "\t\tfor year, group in splitting}\n",
    "\n",
    "pd.Series(chevy_means)\n",
    "\n",
    "# Boolean groupby\n",
    "chevy = auto['name'].str.contains('chevrolet')\n",
    "\n",
    "auto.groupby(['yr', chevy])['mpg'].mean()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "# Create the Boolean Series: under10\n",
    "under10 = (titanic['age'] < 10).map({True:'under 10', False:'over 10'})\n",
    "\n",
    "# Group by under10 and compute the survival rate\n",
    "survived_mean_1 = titanic.groupby(under10)['survived'].mean()\n",
    "print(survived_mean_1)\n",
    "\n",
    "# Group by under10 and pclass and compute the survival rate\n",
    "survived_mean_2 = titanic.groupby([under10,'pclass'])['survived'].mean()\n",
    "print(survived_mean_2)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two new DataFrame methods\n",
    "\n",
    "- idxmax(): row or column label where the maximum value is located\n",
    "- idxmin(): row or column label where the minimum value is located\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "# Extract all rows for which the 'Edition' is between 1952 & 1988: during_cold_war\n",
    "during_cold_war = (medals['Edition'] >= 1952) & (medals['Edition'] <= 1988)\n",
    "\n",
    "# Extract rows for which 'NOC' is either 'USA' or 'URS': is_usa_urs\n",
    "is_usa_urs = medals.NOC.isin(['USA','URS'])\n",
    "\n",
    "# Use during_cold_war and is_usa_urs to create the DataFrame: cold_war_medals\n",
    "cold_war_medals = medals.loc[during_cold_war & is_usa_urs]\n",
    "\n",
    "# Group cold_war_medals by 'NOC'\n",
    "country_grouped = cold_war_medals.groupby('NOC')\n",
    "\n",
    "# Create Nsports\n",
    "Nsports = country_grouped['Sport'].nunique().sort_values(ascending=False)\n",
    "\n",
    "# Print Nsports\n",
    "print(Nsports)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grouping the data**\n",
    "\n",
    "~~~\n",
    "france = medals.NOC == 'FRA'\n",
    "\n",
    "france_grps = medals[france].groupby(['Edition','Medal'])\n",
    "\n",
    "france_grps['Athlete'].count().head(10) # MultiIndex\n",
    "~~~\n",
    "\n",
    "**Reshaping data**\n",
    "\n",
    "~~~\n",
    "france_medals = france_grps['Athlete'].count().unstack()\n",
    "\n",
    "france_medals.head(12) # Single level index\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
